**YC DAY 2**

Good fire - interpretability

  

Satya:

- Energy use has to be justified. Social impact from this ai we’re creating has to be good enough for economy to justify its energy use
- LinkedIn combined design and front end engineering bc of AI
- Memory, tools use / scaffolding, entitlement 
- Software engineer -> software architect 

- In world of ai engineers will just be working more abstractly 
- Still need human in the loop

- Privacy, security, sovereignty needed for ai

- If ai becomes our OS we need these three and for any product 

- Don’t wait for promo to work hard. 

- Work as hard as you can at current role 
- Learn to make teams great

- High ambition and work in team well

- Three important traits:

- Strive to be person who brings clarity in ambiguous situations

- Know the next step

- Bring energy and positivity (especially across the team)
- Can problem solve(over constrained problems)

- Describe project going nowhere and they figured out a path - his favorite interview question 
- HPC(?) related to quantum - high performance computing
- Q: you’re a new grad what would you work on?
- A: vs code and excel

  

Andrej Karpathy:

- map of github graph
- Hugging face is software 2.0
- Software 3.0 is natural language
- Software 2.0 was eating software 1.0 in self driving car code (stitching images done in neural net instead of c++ code)
- Fab llm(?)
- LLMs have properties of OS
- Similar to 1960s when we had time share computers but itll get better 
- Consumer -> corporations -> government for ai which is different from other technologies 
- LLMS can remember SHA hashes
- Have jagged intelligence 
- Prompt injection risks for LLMs
- Kind of a lossy simulation of a savant with cognitive issues
- Opportunities:

- Partial autonomy apps (cursor)

- Have traditional interface with LLM integration
- Package state into a context window before calling LLM
- Orchestrate multiple models( chat models, embedding models)
- Application specific GUI
- Autonomy slider: tab completion, cmd k, cmd L, cmd I
- Perplexity is another good example 

- A lot of products will become partial autonomy 
- Ai does generation and human does verification (make verification easy and fast to win)

- Keep AI on a tight leash to increase

- Waymo had a perfect drive in 2013 and 12 years later we’re still working on this. There is still a lot of supervision
- Mind the demo to product gap 

- Demo is works any
- Product is work all

- Software is tricky similar to driving we can’t just make mistakes and ignore it  
- 2025-2035 is the decade of agents - andrej 
- Autonomy slider is important in any product 
- People are creating docs for LLMs (markdown for LLMs to understand easier)
- Instead of click vercel is making curl so LLMs can get info easier 
- Gitingest allows you to take a github repo and give it to LLM to understand repo better. Just replace GitHub in url with gitingest or deepwiki
- Devin deepwiki
- It’s the 1960s of these OS or LLMs
- Amazing time for software 

  

  

Andrew Ng:

- strong predictor for a startups off of success if execution speed 
- AI speeds up startups 
- Agentic workflow: write essay outline, write a first draft, revise it.

- Iterative workflow

- New agentic orchestration layer(lang chain)
- Concrete ideas let you go faster 

- Concrete: software for hospitals to let patients book mri machine slots online to optimize usage 
- Help you validate idea quick
- Gives clear direction and can be executed quick
- Come from subject matter expert thinking about a problem for a long time. Gut can be good for making decisions
- If data proves otherwise, then pivot 

- AI assisted coding enables rapid engineering so prototyping is easier 
- Insecure code is fine for prototypes running on your machine 
- To pursue innovation, build 20 prototypes
- Even choosing the architecture for a prototype is closer to a 2 way door than a 1 way door 
- AI is emerging tech and the knowledge is not widespread. A deep understanding of AI ie a differentiator 

- Graph db, guard rails, RAG, evals

- Deep learning.ai courses
- Not worried about AGI think it’s kinda overhyped. People should know how to use the tools to get it to do what you want it to do
- Companies overhyped ai for their own promotion 
- If you build a product people really want that is your moat 

  

Cursor:

- Cosine similarity 
- RAG allows large context

  

Lightcone podcast:

- Brian Kaplan education theory
- Find a niche
- Need domain expertise. This is quick to get if you’re smart about it
- SBF, Theranos
- Simulacrum
- Hone in and find 10 people that love your product 
- Find niche and expand (ex: stripe and airbnb, coinbase) 
- Find the wedge
- More agency(?)
- FDSE palantir research

  

  

Anthropic dude:

- the paradox of running a startup:

- Focus is everything 
- But have toFocus on everything hiring, GTM, etc

- Plan your product on where you think foundation models will be in 6 months
- Plan your company based on AGI arriving in 2 years
- Will software commodotize or will quality standards increase 
- What Should ui look like for agents
- Multi modal ui UX (?)
- Will product that are ai first have an advantage over retrofit AI but already have distribution?

- Ai native now vs 6 months from now might be different too

- How can professional and personal assistant agents work together?
- How can you ensure an agent is working on your behalf?
- How can users and enterprises trust semi automated or fully automated teams?
- What happens when human guardrails are removed inside companies?
- What should audits look like in a post AGI world?

- Ai has stronger potential for this than humans bc they could delete notes after audit

- Should a company make public comments that are audit enforced?
- What aspects of alignment need to be solved before long horizon agents are solved?
- TSMC and ASML info isn’t out about semiconductors 
- Does fine tuning have a role to play? Better context management? Small vs large model routing?
- What makes a durable advantage post AGI?
- His moat is liking to solve hard problems 

- This provides a competitive advantage 

- What problems will be hard post AGI?
- Is there an intelligence ceiling for some tasks? Or is more intelligence always better?
- Next couple years everything will move extremely fast 
- Maximize diversity in info diet

- He uses twitter (Jordan fisher, CEO standard AI)

- He thinks you don’t need to be passionate about the domain (100 hour work weeks for 6 months will make you hate any idea) more than caring about cofounders and wanting to make an impact 
- Personal assistant AI that schedules events for you needs to know implicit scheduling rules like power dynamics so don’t say you have a bunch of time 

  
Cloud flare tunnel to show local host