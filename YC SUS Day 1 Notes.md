Sam:
- memory feature 
- Open ai will become more of a companion
- Coming out with open source model
- People don’t know how to fully utilize reasoning models (?)
- Open ai towards super assistant 
- Computer interfaces will be more embedded and natural
- Best time to build company. Ground is shaking
	- Iterate faster and for cheaper than big companies
	- Everyone facing big challenges (startups win)
- Just in time software (?)
- 7 powers
- Get applicants with most impressive things they built

Kaplan(Anthropic):
- Pretraining and RL
- Scaling laws in pretraining
- Length of time saved by ai models is doubling every 7 months
- 3.7 is too eager. 4.0 has improved ability to act as an agent and improved oversight 
	- Improved memory and code quality 
	- Gets incrementally better
	- Excited for unlocking better and better memory 
- Claude will become collaborator 
- AI skeptics are right that AI makes stupid mistakes because ai judgement of whether something makes sense or not isn’t as good as humans 
- Building for use cases where ai can be correct 70% of the time is better than 99% 
- Still need human in the loop for more advanced tasks 
- Value in understanding how these models work and leverage/integrate them 
	- Build at frontier

Francis Chollet(Ndea):
- fluid intelligence does not emerge from pretraining
- *Intelligence*: 
	- Science of making machines capable of performing tasks that would req intelligence by humans
	- 
- Why did pretraining scaling hit a wall?
- Does test-time adaptation scale to AGI?
- Whats next for AI beyond TTA?
- conceptulaizing intellgient systems:
	- static skills (memorized) vs fluid intelligence(on-the-fly)
	- static skills
		- narrow operational area of programs used
		- data hungry program acquisition
	- fluid:
		- broad operational area of programs used(high abstraction)
- ==shortcut rule== you achieve what you target, at the expense of everything else
	- target exam style benchmark -> achieve memorization engine
	- target fluid intelligence benchmark -> achieve innovation engine

- we want AGI that can efficiently pick up new skills and solve unseen problems = innovation
- **arc-agi** requires figuring out new rules on the fly by recombining what you know 
	- easy for humans but hard for AI
	- isn't an indicaator of whether we have AGI or not 
	- ==has resisted pretraining scaling==
	- has helped highlight the rise of test-time adaptation
- *as long as we can easily come up with task that humans can do that AI can't do, then we don't have AGI*
- https://www.envisioning.io/vocab/kaleidoscope-hypothesis#:~:text=In%20practical%20terms%2C%20the%20Kaleidoscope,behaviors%20in%20contextually%20grounded%20scenarios


